{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: embed-anything-gpu in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (0.4.14)\n",
      "Requirement already satisfied: onnxruntime-gpu==1.19.2 in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from embed-anything-gpu) (1.19.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (24.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (3.20.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from onnxruntime-gpu==1.19.2->embed-anything-gpu) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from coloredlogs->onnxruntime-gpu==1.19.2->embed-anything-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from sympy->onnxruntime-gpu==1.19.2->embed-anything-gpu) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\sonam\\anaconda3\\envs\\unsloth\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu==1.19.2->embed-anything-gpu) (3.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install embed-anything-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Run ONNX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from embed_anything import EmbedData, ColpaliModel\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "\n",
    "model: ColpaliModel = ColpaliModel.from_pretrained_onnx(\"starlight-ai/colpali-v1.2-merged-onnx\", None)\n",
    "\n",
    "def process_pdf(files, model:ColpaliModel):\n",
    "    file_embed_data: list[EmbedData] = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            embedding: list[EmbedData] = model.embed_file(str(file), batch_size=1)\n",
    "            file_embed_data.extend(embedding)   \n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding file {file}: {e}\")\n",
    "\n",
    "    return file_embed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Run it on Candle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from embed_anything import EmbedData, ColpaliModel\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import io\n",
    "import torch\n",
    "\n",
    "model: ColpaliModel = ColpaliModel.from_pretrained(\"vidore/colpali-v1.2-merged\", None)\n",
    "\n",
    "def process_pdf(files, model:ColpaliModel):\n",
    "    file_embed_data: list[EmbedData] = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            embedding: list[EmbedData] = model.embed_file(str(file), batch_size=1)\n",
    "            file_embed_data.extend(embedding)   \n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding file {file}: {e}\")\n",
    "\n",
    "    return file_embed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, model):    \n",
    "    query_embedding = model.embed_query(query)\n",
    "    query_embeddings = np.array([e.embedding for e in query_embedding])\n",
    "    return query_embeddings\n",
    "\n",
    "def score(query_embeddings, file_embed_data):\n",
    "    file_embeddings = np.array([e.embedding for e in file_embed_data])\n",
    "    scores = np.einsum(\"bnd,csd->bcns\", query_embeddings, file_embeddings).max(axis=3).sum(axis=2).squeeze()\n",
    "\n",
    "    # Get top pages\n",
    "    top_pages = np.argsort(scores)[::-1][:3]\n",
    "\n",
    "    # Extract file names and page numbers\n",
    "    table = [\n",
    "        [file_embed_data[page].metadata[\"file_path\"].split(\"/\")[-1], file_embed_data[page].metadata[\"page_number\"]]\n",
    "        for page in top_pages\n",
    "    ]\n",
    "\n",
    "    # Print the results in a table\n",
    "    print(tabulate(table, headers=[\"File Name\", \"Page Number\"], tablefmt=\"grid\"))\n",
    "    results_str = tabulate(table, headers=[\"File Name\", \"Page Number\"], tablefmt=\"grid\")\n",
    "\n",
    "    images = [file_embed_data[page].metadata[\"image\"] for page in top_pages]\n",
    "    images = [Image.open(io.BytesIO(base64.b64decode(image))) for image in images]\n",
    "    return images, results_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all PDF files in the directory\n",
    "directory = Path(\"../../test_files\")\n",
    "files = list(directory.glob(\"*.pdf\"))\n",
    "file_embed_data = process_pdf(files, model)\n",
    "query = \"What is the first page of the pdf\"\n",
    "query_embeddings = process_query(query, model)\n",
    "images, results_str = score(query_embeddings, file_embed_data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# show the images side by side using subplots\n",
    "fig, axs = plt.subplots(1, len(images), figsize=(20, 15))\n",
    "for i, image in enumerate(images):\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_on_upload(files):\n",
    "    global embedded_file_data\n",
    "    # Embed the uploaded PDF files\n",
    "    embedded_file_data = process_pdf(files, model)\n",
    "    return f\"Processed {len(files)} PDFs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Gradio app interface\n",
    "def gradio_app(query):\n",
    "    global embedded_file_data\n",
    "    if embedded_file_data is None:\n",
    "        return [], \"No PDFs have been uploaded or processed.\"\n",
    "    \n",
    "    # Process the query and return results\n",
    "    query_embeddings = process_query(query, model)\n",
    "    images, results_str = score(query_embeddings, embedded_file_data)\n",
    "    \n",
    "    return images, results_str\n",
    "# Gradio Interface definition\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# PDF Search and Embedding App\")\n",
    "    \n",
    "    with gr.Column():\n",
    "        pdf_upload = gr.Files(label=\"Upload PDFs\", file_types=[\".pdf\"])\n",
    "        upload_status = gr.Textbox(label=\"Upload Status\", interactive=False)\n",
    "        query_input = gr.Textbox(label=\"Query\")\n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        gallery_output = gr.Gallery(label=\"Top Results Images\")\n",
    "        results_output = gr.Textbox(label=\"Results\", interactive=False)\n",
    "    \n",
    "    # Embed PDFs when files are uploaded\n",
    "    pdf_upload.upload(process_pdf_on_upload, inputs=pdf_upload, outputs=upload_status)\n",
    "    \n",
    "    # Handle the query when submit button is clicked\n",
    "    submit_btn.click(gradio_app, inputs=[query_input], outputs=[gallery_output, results_output])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
